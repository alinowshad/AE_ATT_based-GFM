## Autoencoder Attention-based Global Forecasting Model
#### Abstract:
In several industries, such as retail, tourism, and energy, vast amounts of time series data are generated. Global forecasting models (GFMs) have been successfully employed to train a single model by exploiting a set of time series. However, the performance of global models might diminish when confronted with heterogeneous time series datasets of varying lengths. This study proposes an autoencoder-based clustering approach that initially identifies clusters of homogeneous time series and subsequently trains a separate GFM for each cluster, leveraging the similarities across time series. The proposed autoencoders for time series featurization are designed by combining Long Short-Term Memory (LSTM), convolutional neural network (CNN), and attention mechanisms, with a masking layer incorporated to handle variable lengths in time series. Attention mechanisms facilitate the identification of the most significant features within the input by dynamically weighing the importance of different temporal features. To evaluate the forecasting accuracy of the proposed approach, extensive experiments are conducted across five time series datasets. The results demonstrate the superior performance of the proposed models compared to benchmark models across most datasets in terms of performance measures. Specifically, the autoencoder-based models consistently outperform several benchmark models, including univariate models as well as deep learning benchmarks such as DeepAR and N-BEATS techniques, and some clustering-based models in the existing literature with forecasting approaches similar to ours.
